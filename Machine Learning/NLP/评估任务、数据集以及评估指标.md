# NLP主要任务
* 序列标注:分词，词性标注，命名实体识别
* 分类:文本分类，情感计算
* 句子关系:entailment（分类为蕴含或矛盾），相似度计算
* 文本生成:机器翻译，问答系统，文本摘要
  



# 文本生成评估指标
##  BLEU
  > Bleu是IBM在2002提出的，用于机器翻译任务的评价，发表在ACL，原文题目是“BLEU: a Method for Automatic Evaluation of Machine Translation”。

它的总体思想就是准确率，假如给定标准译文reference，神经网络生成的句子是candidate，句子长度为n，candidate中有m个单词出现在reference，m/n就是bleu的1-gram的计算公式。  
  BLEU还有许多变种。根据n-gram可以划分成多种评价指标，常见的指标有BLEU-1、BLEU-2、BLEU-3、BLEU-4四种，其中n-gram指的是连续的单词个数为n。BLEU-1衡量的是单词级别的准确性，更高阶的bleu可以衡量句子的流畅性。  

### 计算公式

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/54cdf86c-c626-4953-8b41-f0125af3a15b)
![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/6dedaa6d-3375-4ab8-a25f-0fb7772d8274)


* BP是简短惩罚因子，惩罚一句话的长度过短，防止训练结果倾向短句的现象。以c来表示待评价译文的长度，r来表示参考译文的文字长度 
* Pn是基于modified n-gram recision的精确度,主要思路是Reference语句里面如果一个单词片段已经被匹配，那么这个片段就不能再次被匹配，并且一个单词片段只能取一个Reference语句中出现次数的最大值，比如7个the分别在Reference 1 和 2中出现2和1次，所以取2而不是两者相加的3。

### 优缺点
* 优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。
* 缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。

## Rouge
> ROUGE（Recall-Oriented Understudy for Gisting Evaluation）评估指标最早出自chin-yew lin在2003年的论文《ROUGE: Recall-oriented understudy for gisting evaluation》
> 
  ROUGE指标是在机器翻译、自动摘要、问答生成等领域常见的评估指标。
  ROUGE通过将模型生成的摘要或者回答与参考答案（一般是人工生成的）进行比较计算，得到对应的得分。
  ROUGE指标与BLEU指标非常类似，均可用来衡量生成结果和标准结果的匹配程度，不同的是ROUGE基于召回率，BLEU更看重准确率。
  在论文中主要提到了4种方法，分别是Rouge-N、Rouge-L、Rouge-W、Rouge-S。


### ROUGE-N
ROUGE-N 指标计算生成的摘要与相应的参考摘要的 n-gram 召回率，具体的公式为：
![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/59c6d2f1-38b0-4ca3-bc6f-0b0ee3f89529)

其中分母部分计算参考摘要中 n-gram 的个数，分子部分计算参考摘要和自动摘要共有的 n-gram 的个数。

实例：
自动摘要：the cat was found under the bed
参考摘要：the cat was under the bed

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/8f390526-b886-48b9-898b-91d002ec59b1)

> ROUGE-1 = 6/6 = 1   
ROUGE-2 = 4/5 = 0.8

### ROUGE-L
ROUGE-L 指标基于两个文本单元的最长公共序列，计算 F-measure，具体公式如下：

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/1fbf104e-fa49-4ff1-bc85-7ec6b5fcf56d)

其中 X 为参考摘要，长度为 m；Y 为生成摘要，长度为 n；β 为精确率和召回率的比值。

>实例：
自动摘要：police kill the gunman  
参考摘要：police killed the gunman   
R = 3/4   
P = 3/4   
ROUGH-L = F = 3/4 = 0.75   

### ROUGE-W
ROUGE-W 指标在 ROUGE-L 的基础上进行加权计算。

X: [A B C D E F G]
Y1: [A B C D H I K]
Y2: [A H B K C I D]
Y1 和 Y2 的 ROUGH-L 值都为 4/7，但明显 Y1 与参考摘要更加接近，所以作者提出了一个基于最长公共子序列的加权算法。

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/05e2f058-6771-4267-811b-a01812707a05)


### ROUGH-S
ROUGH-S 使用了 skip-grams，在参考摘要和生成摘要进行进行匹配时，不要求 gram 之间是连续的，可跳过几个单词，如 skip-bigram，在产生 grams 时，允许最多跳过两个词。

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/86e16759-2508-44ba-9c29-237dc67bebd9)


>实例：
>例子：cat in the hat
>skip-bigrams：cat in, cat the, cat hat, in the, in hat, the hat


### 优缺点
* 缺点 
是这种方法只能在单词、短语的角度去衡量两个句子的形似度。并不能支持同义词、近义词等语意级别去衡量。比如：  
ref = "I'm very happy!"  
hyp = "I'm very sad!"  
hyp1 = "I'm very cheerful!"  
hyp1和hyp2的rouge得分是一样的。但显然hyp1才是与ref更相近的。
* 优点
是这种方式计算高效，在忽略近义词等情况下，做到比较合理的判断。





参考文档：跟踪NLP进展的博客<a href="https://github.com/sebastianruder/NLP-progress" > Tracking Progress in Natural Language Processing </a> (近期无更新)
