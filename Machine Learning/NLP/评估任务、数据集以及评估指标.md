# NLP主要任务
* 序列标注:分词，词性标注，命名实体识别
* 分类:文本分类，情感计算
* 句子关系:entailment（分类为蕴含或矛盾），相似度计算
* 文本生成:机器翻译，问答系统，文本摘要
  


文本生成
# 文本生成评估指标
##  BLEU
  > Bleu是IBM在2002提出的，用于机器翻译任务的评价，发表在ACL，原文题目是“BLEU: a Method for Automatic Evaluation of Machine Translation”。

它的总体思想就是准确率，假如给定标准译文reference，神经网络生成的句子是candidate，句子长度为n，candidate中有m个单词出现在reference，m/n就是bleu的1-gram的计算公式。  
  BLEU还有许多变种。根据n-gram可以划分成多种评价指标，常见的指标有BLEU-1、BLEU-2、BLEU-3、BLEU-4四种，其中n-gram指的是连续的单词个数为n。BLEU-1衡量的是单词级别的准确性，更高阶的bleu可以衡量句子的流畅性。  

### 计算公式

![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/54cdf86c-c626-4953-8b41-f0125af3a15b)
![image](https://github.com/zjuwispersure/zjuwispersure.github.io/assets/3489254/6dedaa6d-3375-4ab8-a25f-0fb7772d8274)


* BP是简短惩罚因子，惩罚一句话的长度过短，防止训练结果倾向短句的现象。以c来表示待评价译文的长度，r来表示参考译文的文字长度 
* Pn是基于modified n-gram recision的精确度,主要思路是Reference语句里面如果一个单词片段已经被匹配，那么这个片段就不能再次被匹配，并且一个单词片段只能取一个Reference语句中出现次数的最大值，比如7个the分别在Reference 1 和 2中出现2和1次，所以取2而不是两者相加的3。

### 优缺点
* 优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。
* 缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。

## Rouge
> ROUGE（Recall-Oriented Understudy for Gisting Evaluation）评估指标最早出自chin-yew lin在2003年的论文《ROUGE: Recall-oriented understudy for gisting evaluation》
> 
  ROUGE指标是在机器翻译、自动摘要、问答生成等领域常见的评估指标。
  ROUGE通过将模型生成的摘要或者回答与参考答案（一般是人工生成的）进行比较计算，得到对应的得分。
  ROUGE指标与BLEU指标非常类似，均可用来衡量生成结果和标准结果的匹配程度，不同的是ROUGE基于召回率，BLEU更看重准确率。
  在论文中主要提到了4种方法，分别是Rouge-N、Rouge-L、Rouge-W、Rouge-S。








参考文档：跟踪NLP进展的博客<a href="https://github.com/sebastianruder/NLP-progress" > Tracking Progress in Natural Language Processing </a> (近期无更新)
